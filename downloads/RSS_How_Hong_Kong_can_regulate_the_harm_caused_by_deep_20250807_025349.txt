Creators of deepfake pornography may exist in a legal vacuum, with existing laws unable to properly govern or penalise their culpable conduct
As artificial intelligence (AI) technology continues to develop, its utility for ordinary law-abiding citizens grows, along with its potential for abuse. However, the breakneck speed of development often leaves the law playing catch-up in confronting these new societal harms.
The use of AI to create pornographic images of a person without their consent is a growing problem not limited to Hong Kong, and will only grow more prominent as the technology develops.
Deepfakes, which are generated by AI neural networks, allow a person to upload images of a person’s body or face, which are then used to create pornographic images resembling that person, producing deepfake pornography.
While it has long been possible to digitally alter images of real people so as to make them resemble pornography (e.g. by using tools like Photoshop), deepfake pornography can be created completely digitally, in large quantities, instantaneously, and on freely available websites.
A prime example is the use of celebrities’ faces and/or voices with AI tools to create falsified videos or even pornographic photos.
From a lawsuit commenced by movie star Scarlett Johansson against an AI app developer that used her likeness and voice to create ultra-realistic images, to singer Taylor Swift being the subject of deepfake pornography, the escalation in the purposes and culpability in using deepfake technology has led to several countries implementing legislation to combat this new trend.